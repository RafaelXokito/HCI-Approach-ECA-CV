% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%\urlstyle{rm}
%
\begin{document}
%
\title{Human-Computer Interaction approach with Empathic Conversational Agent and Computer Vision}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{First Author\inst{1}\orcidID{0000-1111-2222-3333} \and
Second Author\inst{2,3}\orcidID{1111-2222-3333-4444} \and
Third Author\inst{3}\orcidID{2222--3333-4444-5555}}
%
\authorrunning{F. Author et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Princeton University, Princeton NJ 08544, USA \and
Springer Heidelberg, Tiergartenstr. 17, 69121 Heidelberg, Germany
\email{lncs@springer.com}\\
\url{http://www.springer.com/gp/computer-science/lncs} \and
ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany\\
\email{\{abc,lncs\}@uni-heidelberg.de}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
The abstract should briefly summarize the contents of the paper in
150--250 words.

\keywords{First keyword  \and Second keyword \and Another keyword.}
\end{abstract}
%
%
%

\section{Introduction}

 % necessity of a machine having empathy, through computacional methods, to improve and make more realistic HCI 
 
 % explain how new technologies try to solve this problem (https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10091537)
 
 % introduce HCI, DL, ER and CA
 
 % introduction of our paper 
  
 % contribuitions
 
 % estrutura geral
 
 
%Contributions:
%1. Explanation of how Deep Learning impact HCI nowadays
%2. A brief review of Emotion Recognition and Conversational agents topics
%3. Exposure of the main used methods and datasets used for emotion recognition and
%conversational agents
%4. A proposal of a taxonomy regarding HCI, DL, CA, and ER.
%5. The proposal of an architecture of a Human Computer Interaction approach with an Empathic Conversational Agent and Computer Vision

\section{Background}

%% Introduce the lacking of HCI nowadays Deep Learning.

% Since people have become more informed, they need a high level of computer intelligence [1], [2]. Human-computer interaction (HCI) is not limited to original hardware-related communication. Certain smarter communication techniques are appearing gradually in the life of people like a sequence of more intellectual techniques relevant to voice recognition [3], face recognition, and gesture recognition.  https://ieeexplore.ieee.org/document/10091537

% Similarly, machines that are able to perceive and interact with moving people, either in physical or virtual environments, must have a notion of how people move. Since human motion is the result of both physical limitations (e.g. torque exerted by muscles, gravity, moment preservation) and the intentions of subjects (how to perform an intentional motion), motion modeling is a complex task that should be ideally learned from observations.  https://ieeexplore.ieee.org/document/8099980

% Introduce deep learning - Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Introduce the subsections of Deep Learning namely Supervised Learning. Explain briefly what is suppervised learning, and which options we have available.  https://www.nature.com/articles/nature14539#Sec4

% Introduce Supervised Learning (Reduce the size of this paragraph to half, and add the information that this Paper will only focus on methods of Supervised Learning.) - The most common form of machine learning, deep or not, is supervised learning. Imagine that we want to build a system that can classify images as containing, say, a house, a car, a person or a pet. We first collect a large data set of images of houses, cars, people and pets, each labelled with its category. During training, the machine is shown an image and produces an output in the form of a vector of scores, one for each category. We want the desired category to have the highest score of all categories, but this is unlikely to happen before training. We compute an objective function that measures the error (or distance) between the output scores and the desired pattern of scores. The machine then modifies its internal adjustable parameters to reduce this error. These adjustable parameters, often called weights, are real numbers that can be seen as 'knobs' that define the input–output function of the machine. In a typical deep-learning system, there may be hundreds of millions of these adjustable weights, and hundreds of millions of labelled examples with which to train the machine.  https://www.nature.com/articles/nature14539#Sec4

% Introduce Deep Learning phases to train a Supervised Learning model, identify the purpose, gather the data (How important is the data for training), pre-process the data (how important is the quality of the data), train the model, optimizing based on the validation, and test.

% From the implementation perspective, in the last years, FER systems developed using different types of artificial neural networks (ANNs), which proved to have better results than using traditional machine learning methods based on feature descriptors such as histogram of oriented gradients (HOG), or local binary pattern (LBP) combined with data classifiers such as support vector machine (SVM), k-nearest neighbors (KNN) or random forest. As demonstrated in other detection or recognition processes based on ANNs, people’s emotions can also be accurately detected and recognized in a subject-independent way by building a model through the analysis of a collection of training data from different individuals, including skeletal movements [1]. The use of ANNs for emotion detection and recognition opened many opportunities for practical applications, especially in fields such as healthcare, security, business, education, or manufacturing.  https://www.mdpi.com/1424-8220/23/16/7092

%% Introduce DL techniques, like transfer learning, GANs..
% {Regarding the computer vision domain, neural networks have been successfully used in image classification and more specifically, face identification and facial emotion recognition applications. Besides the main utility in surveillance systems, neural networks have also begun to be used in medical diagnosis applications (to identify patient conditions [69,94,95]) or in applications that involve interaction with a user [96,97,98,99,100].

%The specific requirements in the field of face identification and facial emotion recognition have been solved with different types of neural network architectures. For instance, pre-trained networks can be used for the following tasks:
%Classification, which can apply pre-trained networks directly to classification tasks [34,35,38,53,80].
%Feature extraction, which is pre-trained network which can be used as a feature extractor using the activation layers as features, and these layers can be used to train other machine learning models, such as a support vector machine (SVM) [62,77,83,90,101].
%Transfer learning, in which the layers of a neural network trained on one dataset are adjusted and reused to test a new dataset [54,73,102,103,104]}  https://www.mdpi.com/1424-8220/23/16/7092.

% Show examples of each one, Classification, Feature extraction (landmarks extraction), and Transfer learning.

% ER  (Face, Pose, Text, Speech)

% CA (Embodied, Interaction, Domain, Goal)

\section{Datasets}

% Introduce the main datasets used.

\section{Methods}

% Introduce the main methods used.

\section{Proposed solution}

% description of characteristics
% prototype ???

\section{Future work and conclusions}


\begin{credits}
\subsubsection{\ackname} A bold run-in heading in small font size at the end of the paper is
used for general acknowledgments, for example: This study was funded
by X (grant number Y).

\subsubsection{\discintname}
It is now necessary to declare any competing interests or to specifically
state that the authors have no competing interests. Please place the
statement with a bold run-in heading in small font size beneath the
(optional) acknowledgments\footnote{If EquinOCS, our proceedings submission
system, is used, then the disclaimer can be provided directly in the system.},
for example: The authors have no competing interests to declare that are
relevant to the content of this article. Or: Author A has received research
grants from Company W. Author B has received a speaker honorarium from
Company X and owns stock in Company Y. Author C is a member of committee Z.
\end{credits}
%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\bibliographystyle{splncs04}
\bibliography{bibliography}
%
\end{document}
